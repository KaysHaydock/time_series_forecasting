{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f56155b6-5aaf-4439-89ed-a5e00f043fae",
   "metadata": {},
   "source": [
    "# Final Report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581508ba-629d-47d8-a0df-20269ce4cc20",
   "metadata": {},
   "source": [
    "## Forecasting Paediatric Emergency Department Attendances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f6c88e-88c7-4f46-bb18-cd3465649938",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8207778c-b0f3-41de-8b9b-cf61fcc9d25f",
   "metadata": {},
   "source": [
    "## Executive Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca7c4a6-88cb-4015-9833-3c3afd62cca2",
   "metadata": {},
   "source": [
    "**Background**\n",
    "\n",
    "Accurate forecasting of paediatric emergency department (ED) attendances is essential for NHS Acute Trusts to optimise staffing and resource allocation. Although improving ED performance often requires additional staffing and infrastructure, the ability to accurately forecast patient attendances enables managers to optimise the use of available resources [[1]](https://www-sciencedirect-com.uoelibrary.idm.oclc.org/science/article/pii/S1386505618302429). This study aims to evaluate multiple time series forecasting models to predict daily attendances over a 28-day horizon, supporting workforce planning.\n",
    "\n",
    "**Methods**\n",
    "\n",
    "Historical daily attendance data from 2014 to 2017 was used to develop forecasting models. A benchmark model was selected after trialling Naive 1 and Seasonal Naive, with Naive 1 chosen due to better performance. Naive 1 forecasting assumes that the next day's attendance is equal to the last observed value. The benchmark model was compared against Auto-Regressive Integrated Moving Average (ARIMA) and Facebook's Prophet. Model performance was evaluated using Mean Absolute Error (MAE) and Winkler Scores for 80% and 90% prediction intervals. Time series cross-validation was also employed to ensure robustness.\n",
    "\n",
    "**Results**\n",
    "\n",
    "The Naive 1 benchmark model achieved a MAE of 9.66, with 80% and 90% prediction interval scores of 96.15 and 123.41, respectively. Prophet outperformed Naive 1, achieving a MAE of 6.11, with 80% and 90% prediction interval scores of 24.43 and 25.59, respectively. The results indicate that Prophet provides more accurate short-term forecasts with significantly tighter prediction intervals, improving its suitability for operational decision-making and resource allocation. The results indicate that attendances are typically higher on weekends and Mondays, suggesting that increased staffing at the ED may be beneficial on these days.\n",
    "\n",
    "\n",
    "**Conclusions**\n",
    "\n",
    "This study establishes a validated forecasting approach for the ED, demonstrating that Prophet significantly improves upon naive forecasting methods. The recommended model incorporates UK public holidays, providing a practical and high-quality forecasting method. Future research could explore the impact of additional external factors, such as weather conditions, school term dates, or local outbreaks of infectious diseases, to further refine forecasting accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f0c9f6-4c4a-4b97-81d8-663d0c8eacff",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da778aff-19d0-4387-95b5-148b85ea150c",
   "metadata": {},
   "source": [
    "## 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9463ef3b-37ee-46d5-9b48-6d35d89b5c37",
   "metadata": {},
   "source": [
    "#### **1.1 Problem Background**\n",
    "Accurate forecasting of paediatric emergency department attendances is essential for optimising NHS staffing levels. Unanticipated surges in patient numbers can lead to longer waiting times, increased staff workload and resource strain.\n",
    "\n",
    "The NHS Acute Trust requires a reliable forecasting model to predict the attendances over the next 28 days. This will help in resource planning and staffing adjustments.\n",
    "\n",
    "This report aims to:\n",
    "\n",
    "- Develop a reliable forecasting model for the next 28 days.\n",
    "- Identify weekly and seasonal trends to inform workforce planning.\n",
    "- Recommend an approach that NHS analysts can implement in practice.\n",
    "\n",
    "#### **1.2 Data Overview**\n",
    "The time series dataset provided (`paediatrics_train.csv`) contains:\n",
    "- **Date column**: 'date' (YYYY-MM-DD format)\n",
    "- **Attendance count**: 'paeds_ed_attends' (integer)\n",
    "\n",
    "The time series data spans from **01/04/2014 to 19/02/2017**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe57455-f91e-4848-a792-59f894b4075f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f82aaaa5-1ff6-40a1-8021-711c9a445b7e",
   "metadata": {},
   "source": [
    "## 2. Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2134df18-b6a2-4793-ae06-67f8de14a6af",
   "metadata": {},
   "source": [
    "To better understand the patterns and seasonality of the paediatric ED attendances data, several analyses were conducted and these can be found **[here](01_data_exploration.ipynb)**.\n",
    "\n",
    "#### **2.1 Seasonality Observations:**\n",
    "\n",
    "\n",
    "- ##### **Monthly Seasonality:**\n",
    "Attendances fluctuate across months with an increase in the winter months (November and December) when compared to summer months. With the exception of March having a slight rise in attendances. Some months exhibited higher variability with outliers in March and low outliers in August.\n",
    "\n",
    "\n",
    "- ##### **Weekly Attendance Trends:**\n",
    "Attendances tend to be higher near weekends, particularly on Sundays and Mondays. The interquartile range (IQR) is also wider for these days, indicating greater variability in patient numbers.\n",
    "\n",
    "\n",
    "#### **2.2 Stationarity Tests: Augmented Dickey-Fuller (ADF), Kwiatkowski-Phillips-Schmidt-Shin (KPSS):**\n",
    "While the visualisations are suggesting strong weekly and monthly seasonality fluctuations, the ADF and KPSS statistical tests confirm that the data is stationary. Since both tests suggest the data is stationary, differencing *d* is likely not needed as much when implementing the ARIMA model.\n",
    "\n",
    "> **ADF Test** (Null Hypothesis: Data is non-stationary)  \n",
    "> - ADF Statistic: **-5.1146**, p-value: **0.0000** (Since the p-value is less than the typical significance level of 0.05, the null hypothesis is rejected, indicating that the data is stationary.)  \n",
    "\n",
    "> **KPSS Test** (Null Hypothesis: Data is stationary)  \n",
    "> - KPSS Statistic: **0.3399**, p-value: **0.1000** (Since the p-value is greater than 0.05, we fail to reject the null hypothesis, which supports the conclusion that the data is stationary. \n",
    "\n",
    "#### **2.3 Autocorrelation (ACF) and Partial Autocorrelation (PACF) Plot Analysis:**\n",
    "- The ACF shows a gradual decline in autocorrelation values, suggesting that past values influence future attendances.\n",
    "- The PACF Function plot shows significant spikes for the first 2-4 lags, followed by a rapid drop-off."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e734b2b8-dc17-408e-bc4e-3445fada869d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c266a109-3013-4e2f-b46a-7464eb4145d8",
   "metadata": {},
   "source": [
    "## 3. Model Selection & Forecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be0aca4-659d-4666-b4e2-1b247d982696",
   "metadata": {},
   "source": [
    "### 3.1. <u>**Naive Models**</u> \n",
    "\n",
    "The model selection process began with the implementation of two simple forecasting models: Naive 1 and Seasonal Naive. These models were chosen as initial benchmarks due to their simplicity and ease of implementation, providing a clear reference point for evaluating the performance of more complex models. Naive 1 will take the most recent observation as the predictor for future values, making it a useful baseline for comparison. Seasonal Naive extends this by assuming that the forecast will follow the last observed value from the same season (for example the same day of the week), making it more suited for seasonal patterns. The best performing model out of the two was **Naive 1** which had a much lower MAE score and was used as the baseline of this study.\n",
    "\n",
    "   \n",
    "- **MAE:** 9.66, 80% PI: 96.15, 90% PI: 123.41\n",
    "- **Strength:** Simple and computationally efficient\n",
    "- **Weakness:** Unable to capture trends or seasonality\n",
    "\n",
    "Formula: $\\hat{y}_t = y_{t-1}$\n",
    "\n",
    "---\n",
    "  \n",
    "### 3.2 <u>**Auto-Regressive Integrated Moving Average (ARIMA)**</u>\n",
    "The next model explored was ARIMA, which is a statistical analysis model. The components which make this model up are:\n",
    "\n",
    "- Autoregressive (AR) predicting future values bases on a linear combination of past values\n",
    "- Integrated (I) applying differencing to remove any trends from the data\n",
    "- Moving Average(MA), incorporating past errors into the prediction process. This model works best with stationary data and tests within the Exploratory Data Analysis chapter 2, were carried out to confirm this.\n",
    "\n",
    "Since ARIMA models work best with stationary data, preliminary statistical tests were conducted to assess stationarity. The Augmented Dickey-Fuller (ADF) test indicated strong stationarity *(p-value: 0.0000)*, while the Kwiatkowski-Phillips-Schmidt-Shin (KPSS) test confirmed no evidence against stationarity *(p-value: 0.1000)*. This suggested that differencing (I component) might not be necessary.\n",
    "\n",
    "#### 3.2.1 **Auto ARIMA**\n",
    "To optimise model selection, an Auto ARIMA approach was used, which automatically determined the best ARIMA configuration based on statistical criteria. The best-performing model was identified as ARIMA(0,1,1) (0,0,2,7), capturing both trend and autoregressive components while accounting for weekly seasonality. Auto ARIMA was also used to initially select the best parameters for this study. \n",
    "   \n",
    "- **MAE:** 7.78, 80% PI: 35.03, 90% PI: 38.36\n",
    "- (0, 1, 1), (0, 0, 2, 7)\n",
    "- Captured trend and autoregressive components\n",
    "- Performed worse than Prophet in terms of both MAE and prediction intervals\n",
    "\n",
    "#### 3.2.2 **Manual ARIMA Models**\n",
    "To further validate the Auto ARIMA results, two additional manual ARIMA models were implemented with cross validation to explore whether slight modifications would lead to better or worse performance. These models were carefully chosen based on the stationarity results and seasonality of the dataset.\n",
    "\n",
    "**ARIMA(1, 1, 0) (1, 0, 0, 7)** – Higher MAE of 8.79\n",
    "\n",
    "Reason for selection:\n",
    "- Introduced an autoregressive term (AR=1) to see if incorporating past values directly would improve predictions.\n",
    "- Maintained differencing (I=1), though it may not have been necessary given stationarity.\n",
    "- Excluded a moving average (MA=0), potentially reducing its ability to adjust for short-term fluctuations.\n",
    "- Seasonal component (1, 0, 0, 7) was included to capture weekly patterns.\n",
    "\n",
    "**ARIMA(2, 1, 0) (1, 0, 0, 7)** – Higher MAE of 8.89\n",
    "\n",
    "Reason for selection:\n",
    "- Increased the autoregressive component to AR=2, testing whether a longer memory of past values could improve performance.\n",
    "- Maintained differencing (I=1) though, as stationarity tests suggested, this may have been unnecessary.\n",
    "- No moving average component (MA=0), reducing short-term adaptability.\n",
    "- Seasonal component (1, 0, 0, 7) was included to acknowledge weekly seasonality.\n",
    "\n",
    "---\n",
    "\n",
    "### 3.3 <u>**Prophet**</u>\n",
    "The final model used in this study was Prophet, designed to handle various components of a time series such as trend, seasonality and external factors such as holidays. Given the nature of the paediatric ED attendances where there may be shifts in demand seasonally, Prophet was a good candidate for this study. One thing to note is that computationally, this model is much more intensive when compared to Naive and ARIMA. One thing to note was Prophets use of Monte Carlo sampling for Prediction Intervals (PIs), which means that the intervals may vary across different runs unless a random_state is set, though the predicted values (yhat) remain unaffected [[2]](https://facebook.github.io/prophet/docs/diagnostics.html).\n",
    "\n",
    "   \n",
    "- **MAE:** 6.11, 80% PI: 24.43, 90% PI: 25.59\n",
    "- A flexible time series model incorporating trend, seasonality and holiday effects\n",
    "- Configured with UK public holidays\n",
    "- Outperformed both Naive 1 and ARIMA in all accuracy metrics\n",
    "\n",
    "---\n",
    "\n",
    "Each model was evaluated based on forecast accuracy metrics. Cross validation was used in each model to ensure robustness and to give a more balanced view of the behaviour.\n",
    "\n",
    "#### **3.4 Model Evaluation Metrics using Cross Validation**\n",
    "\n",
    "| Model | MAE | Winkler Score (80%) | Winkler Score (90%) |\n",
    "|--------|------|------|----------------|\n",
    "| **Prophet (with UK Holidays)** | 6.11 | 24.43 | 25.59 |\n",
    "| Prophet (with Weekly Seasonality) |6.13|24.21|30.11|\n",
    "| Prophet (with Monthly Seasonality) |6.19|25.45|32.68|\n",
    "| Prophet (Baseline Model) |6.33|24.54|30.32|\n",
    "| **ARIMA Auto (0, 1, 1), (0, 0, 2, 7)**| 7.78 | 35.03 | 38.36 |\n",
    "| ARIMA (1, 1, 0), (1, 0, 0, 7)|8.79|60.91|78.18|\n",
    "| ARIMA (1, 1, 0), (0, 0, 0, 7)|8.89|58.65|75.27|\n",
    "| **Naive 1 (baseline)** | 9.66 | 96.15 | 123.41 |\n",
    "| Seasonal Naive|10.48|42.16|51.99|\n",
    "\n",
    "\n",
    "<i> Table 1: Results of various model configurations</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf940b65-dcf5-46e4-828d-d7755c0ffacd",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c7797f-552e-4e87-8365-d49d69d951fe",
   "metadata": {},
   "source": [
    "## 4. Results & Forecast Visualisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a659bf87-e342-46d7-b5fe-0f8fa7e45a17",
   "metadata": {},
   "source": [
    "- In *Image 1*, the Naive 1 model simply projects the last observed value into the future, which results in predictions that remain static and do not track the fluctuations of the test data. As time progresses, the prediction intervals widen, indicating growing uncertainty about future values.\n",
    "  \n",
    "- *Image 2* displays the Auto ARIMA model's predictions. Compared to Naive 1, this model performs better by capturing the fluctuations and trends in the data, following the peaks and troughs with greater accuracy. However, towards the end of the forecast, the prediction intervals expand, suggesting increased uncertainty as the forecast horizon lengthens.\n",
    "\n",
    "  \n",
    "- *Image 3* shows the performance of the Prophet model, which delivers promising results. The predictions closely align with the test data, and the prediction intervals are much narrower, indicating more confidence in the forecasts for the given period.\n",
    "\n",
    "<img src=\"images/naive_graph.png\" width=\"600\"/>\n",
    "\n",
    "<i>Image 1: Naive 1 Predictions</i>\n",
    "\n",
    "---\n",
    "\n",
    "<img src=\"images/auto_arima_graph.png\" width=\"600\"/>\n",
    "\n",
    "<i>Image 2: ARIMA Predictions</i>\n",
    "\n",
    "---\n",
    "\n",
    "<img src=\"images/prophet_graph.png\" width=\"600\"/>\n",
    "\n",
    "<i>Image 3: Prophet Predictions. See [here](images/prophet_predictions.png) for detailed predictions</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ffb11ef-4dc7-443c-a112-c65f33922861",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422149f0-aef1-4940-89ac-3a8db06a2508",
   "metadata": {},
   "source": [
    "## 5. Discussion & Insights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc3681f1-6f96-4576-9b17-4d35af244307",
   "metadata": {},
   "source": [
    "#### **5.1 Key Observations**\n",
    "\n",
    "- **Weekly seasonality:** Higher attendances on **Sundays and Mondays** as seen in *Image 4*.\n",
    "- **Monthly trends:** Spikes observed in **March, November and December**.\n",
    "- **Prophet performed best**, it had a significantly lower MAE with a difference of 36.8% when comparing to the baseline model ( 9.66 vs. 6.11), meaning it made smaller forecasting errors.\n",
    "\n",
    "<img src=\"images/box_plots.png\" width=\"600\"/>\n",
    "\n",
    "<i>Image 4: Weekly and Monthly Boxplots</i>\n",
    "\n",
    "#### **5.2 Strengths**\n",
    "- This study focuses on well-known forecasting methods that are free and open source, this is relevant to the NHS in terms of keeping costs to a minimum.\n",
    "- Prophet's accuracy demonstrates promising predictions with capturing seasonal patterns, especially in the short-term forecasting which is vital in NHS staffing decisions.\n",
    "- Using a benchmarking forecasting method as Monks et al. [[3]](https://bmcmedinformdecismak.biomedcentral.com/articles/10.1186/s12911-023-02218-z) describes, is critical for assessing other, more complex forecasting methods. This study followed that approach.\n",
    "\n",
    "#### **5.3 Limitations**\n",
    "- The recommended forecasting tool Prophet, will still need further validation. If there is a change in workflow or a new intervention within the ED department, this could shift future patterns.\n",
    "- The dataset does not include **external factors (e.g. weather forecasts, major events** such as sporting events etc).\n",
    "- This model might decline when trying to forecast further than 28 days with longer-term predictions being more uncertain.\n",
    "- Some outliers may impact forecast accuracy.\n",
    "\n",
    "#### **5.4 Future Improvements**\n",
    "- **Consider Neural Networks as a forecasting tool** Although computationally much more expensive, it could provide improvements in the metrics collected for model performance.\n",
    "- **Incorporate exogenous variables** (e.g. school holidays or flu seasons). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3c4777-54ea-4c8b-863b-a7a1fbc72c7a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a42e0d-77a4-484b-9388-77a35d893cec",
   "metadata": {},
   "source": [
    "## 6. Conclusion & NHS Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "713b766e-fbec-4be5-8b62-d17ca4d39012",
   "metadata": {},
   "source": [
    "#### **6.1 Summary of Findings**\n",
    "- Best Model: Prophet, especially when including UK public holidays, it was found to be the best performer in terms of MAE and prediction intervals.\n",
    "- Reliability for Short-term Forecasting: The selected models, particularly Prophet, can be trusted for staffing decisions over a short period (28-day forecast). This could be ran at the beginning of each working week for the following 28 days.\n",
    "- Peak attendances seem to occur on Sundays and Mondays, suggesting increased staff allocation would be beneficial.\n",
    "\n",
    "#### **6.2 Recommendations**\n",
    "- NHS should increase staffing levels on high-attendance days. This is based on the weekly seasonality and trends found.  \n",
    "- Update forecasts monthly, even weekly to capture new seasonal trends.  \n",
    "- Consider integrating real-time data sources for improved accuracy. Such as local flu outbreaks and school holidays in the surrounding areas.\n",
    "- Staff should be trained in using this forecasting tool and adjusting or fine tuning parameters if necessary.\n",
    "\n",
    "#### **6.3 Conclusion**\n",
    "This study aimed to explore various time series forecasting models including Naive, ARIMA and Prophet for helping predict the next 28 days of paediatric ED attendances. The Naive model served as a baseline, while ARIMA effectively captured trends and seasonality. However, the Prophet model, with its flexibility to handle seasonality and trends outperformed the others for short-term forecasting.\n",
    "\n",
    "\n",
    "While this study successfully demonstrated the application of several forecasting techniques for these predictions, it highlights the importance of continuous model evaluation and adaptation to real-time data. The findings from this research will help healthcare professionals make more informed decisions about staffing and resource allocation, ultimately improving service delivery within the emergency department."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29843473-4d55-4ef6-9a65-7614c7aa8a05",
   "metadata": {},
   "source": [
    "*Page 6*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
